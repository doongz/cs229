# CS229: Machine Learning

## Introduction

- 所属大学：Stanford
- 授课老师：Andrew Ng
- 先修要求：高数，概率论，需要较深厚的数学功底
- 编程语言：Python
- 课程难度：🌟🌟🌟🌟
- 预计学时：A month
- 学年：Fall 2022-23

吴恩达讲授，一门研究生课程，所以更偏重数学理论；

不满足于调包而想深入理解算法本质，或者有志于从事机器学习理论研究的同学可以学习这门课程。

课程网站上提供了所有的课程 notes，写得非常专业且理论，需要一定的数学功底。

**Course Description**

This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include: 

- supervised learning (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); 
- unsupervised learning (clustering, dimensionality reduction, kernel methods); 
- learning theory (bias/variance tradeoffs, practical advice); 
- reinforcement learning and adaptive control. 

The course will also discuss recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing.

## Resources

- 课程网站：http://cs229.stanford.edu
- 课程视频：2018年 https://www.bilibili.com/video/BV1JE411w7Ub
- 课程教材：无
- 课程作业：参见课程网站
- 实验参考：所有资源都汇总在 [PKUFlyingPig/CS229 - GitHub](https://github.com/PKUFlyingPig/CS229) 中

## Lecture

- Lecture 1: [Introduction](./Lecture/Lecture-1-Introduction)
- Lecture 2: Supervised learning setup. LMS. `Sections 1.1, 1.2 of main notes`
- Lecture 3: Weighted Least Squares. Logistic regression. Newton's Method `Sections 1.3, 1.4, 2,1, 2.3 of main notes`
- Lecture 4: Dataset split; Exponential family. Generalized Linear Models. `Section 2.2 and Chapter 3 of main notes`
- Lecture 5: Gaussian discriminant analysis. Naive Bayes. `Section 4.1, 4.2 of main notes`
- Lecture 6: Naive Bayes, Laplace Smoothing.
- Lecture 7: Kernels; SVM `Chapter 5`
- Lecture 8: Neural Networks 1 `Sections 7.1, 7.2`
- Lecture 9: Neural Networks 2 (backprop) `Section 7.3`
- Lecture 10: [Bias-variance tradeoff, regularization](./Lecture/Lecture-10-Bias-variance-tradeoff®ularization) `Sections 8.1, 9.1, 9.3`
- Lecture 11: [Decision trees](./Lecture/Lecture-11-Decision-trees)
- Lecture 12: Boosting
- Lecture 13: [K-Means. GMM. Expectation Maximization.](./Lecture/Lecture-13-K-Means)
- Lecture 14: EM, PCA
- Lecture 15: [ML Advice](./Lecture/Lecture-15-ML-Advice)
- Lecture 16: [Other learning settings. Large language models & foundation models](./Lecture/Lecture-16-Other-learning-settings)
- Lecture 17: Basic concepts in RL, value iteration, policy iteration.
- Lecture 18: Model-based RL, value function approximator
- Lecture 19: fairness, algorithmic bias, explainability, privacy
- Lecture 20: fairness, algorithmic bias, explainability, privacy

---

- TA Lecture 1: [Linear Algebra Review](./TALecture/TALecture-1-Linear-Algebra)
- TA Lecture 2: [Probability Review](./TALecture/TALecture-2-Probability)
- TA Lecture 3: [Python/Numpy](./TALecture/TALecture-3-Python-Numpy)
- TA Lecture 4: [Evaluation Metrics](./TALecture/TALecture-4-Evaluation-Metrics)
- TA Lecture 5: [Midterm Review](./TALecture/TALecture-5-Midterm)
- TA Lecture 6: Deep Learning (Convnets)
- TA Lecture 7: [GANs](./TALecture/TALecture-7-GANs)
