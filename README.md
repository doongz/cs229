# CS229: Machine Learning

## Introduction

- æ‰€å±å¤§å­¦ï¼šStanford
- æˆè¯¾è€å¸ˆï¼šAndrew Ng
- å…ˆä¿®è¦æ±‚ï¼šé«˜æ•°ï¼Œæ¦‚ç‡è®ºï¼Œéœ€è¦è¾ƒæ·±åšçš„æ•°å­¦åŠŸåº•
- ç¼–ç¨‹è¯­è¨€ï¼šPython
- è¯¾ç¨‹éš¾åº¦ï¼šğŸŒŸğŸŒŸğŸŒŸğŸŒŸ
- é¢„è®¡å­¦æ—¶ï¼šA month
- å­¦å¹´ï¼šFall 2022-23

å´æ©è¾¾è®²æˆï¼Œä¸€é—¨ç ”ç©¶ç”Ÿè¯¾ç¨‹ï¼Œæ‰€ä»¥æ›´åé‡æ•°å­¦ç†è®ºï¼›

ä¸æ»¡è¶³äºè°ƒåŒ…è€Œæƒ³æ·±å…¥ç†è§£ç®—æ³•æœ¬è´¨ï¼Œæˆ–è€…æœ‰å¿—äºä»äº‹æœºå™¨å­¦ä¹ ç†è®ºç ”ç©¶çš„åŒå­¦å¯ä»¥å­¦ä¹ è¿™é—¨è¯¾ç¨‹ã€‚

è¯¾ç¨‹ç½‘ç«™ä¸Šæä¾›äº†æ‰€æœ‰çš„è¯¾ç¨‹ notesï¼Œå†™å¾—éå¸¸ä¸“ä¸šä¸”ç†è®ºï¼Œéœ€è¦ä¸€å®šçš„æ•°å­¦åŠŸåº•ã€‚

**Course Description**

This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include: 

- supervised learning (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); 
- unsupervised learning (clustering, dimensionality reduction, kernel methods); 
- learning theory (bias/variance tradeoffs, practical advice); 
- reinforcement learning and adaptive control. 

The course will also discuss recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing.

## Resources

- è¯¾ç¨‹ç½‘ç«™ï¼šhttp://cs229.stanford.edu
- è¯¾ç¨‹è§†é¢‘ï¼š2018å¹´ https://www.bilibili.com/video/BV1JE411w7Ub
- è¯¾ç¨‹æ•™æï¼šæ— 
- è¯¾ç¨‹ä½œä¸šï¼šå‚è§è¯¾ç¨‹ç½‘ç«™
- å®éªŒå‚è€ƒï¼šæ‰€æœ‰èµ„æºéƒ½æ±‡æ€»åœ¨ [PKUFlyingPig/CS229 - GitHub](https://github.com/PKUFlyingPig/CS229) ä¸­

## Lecture

- Lecture 1: [Introduction](./Lecture/Lecture-1-Introduction)
- Lecture 2: Supervised learning setup. LMS. `Sections 1.1, 1.2 of main notes`
- Lecture 3: Weighted Least Squares. Logistic regression. Newton's Method `Sections 1.3, 1.4, 2,1, 2.3 of main notes`
- Lecture 4: Dataset split; Exponential family. Generalized Linear Models. `Section 2.2 and Chapter 3 of main notes`
- Lecture 5: Gaussian discriminant analysis. Naive Bayes. `Section 4.1, 4.2 of main notes`
- Lecture 6: Naive Bayes, Laplace Smoothing.
- Lecture 7: Kernels; SVM `Chapter 5`
- Lecture 8: Neural Networks 1 `Sections 7.1, 7.2`
- Lecture 9: Neural Networks 2 (backprop) `Section 7.3`
- Lecture 10: [Bias-variance tradeoff, regularization](./Lecture/Lecture-10-Bias-variance-tradeoffÂ®ularization) `Sections 8.1, 9.1, 9.3`
- Lecture 11: [Decision trees](./Lecture/Lecture-11-Decision-trees)
- Lecture 12: Boosting
- Lecture 13: [K-Means. GMM. Expectation Maximization.](./Lecture/Lecture-13-K-Means)
- Lecture 14: EM, PCA
- Lecture 15: [ML Advice](./Lecture/Lecture-15-ML-Advice)
- Lecture 16: [Other learning settings. Large language models & foundation models](./Lecture/Lecture-16-Other-learning-settings)
- Lecture 17: Basic concepts in RL, value iteration, policy iteration.
- Lecture 18: Model-based RL, value function approximator
- Lecture 19: fairness, algorithmic bias, explainability, privacy
- Lecture 20: fairness, algorithmic bias, explainability, privacy

---

- TA Lecture 1: [Linear Algebra Review](./TALecture/TALecture-1-Linear-Algebra)
- TA Lecture 2: [Probability Review](./TALecture/TALecture-2-Probability)
- TA Lecture 3: [Python/Numpy](./TALecture/TALecture-3-Python-Numpy)
- TA Lecture 4: [Evaluation Metrics](./TALecture/TALecture-4-Evaluation-Metrics)
- TA Lecture 5: [Midterm Review](./TALecture/TALecture-5-Midterm)
- TA Lecture 6: Deep Learning (Convnets)
- TA Lecture 7: [GANs](./TALecture/TALecture-7-GANs)
